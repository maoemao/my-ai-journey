# LangChain å¤šæ¨¡æ€è¾“å…¥ä»¥åŠè‡ªå®šä¹‰è¾“å‡º



------



## **ğŸ§© ä¸€ã€LangChain å¤šæ¨¡æ€è¾“å…¥ï¼ˆMulti-modal Inputï¼‰**



### **1ï¸âƒ£ èƒŒæ™¯**

LangChain ä»¥å‰ï¼ˆv0.xï¼‰ä¸»è¦é¢å‘æ–‡æœ¬è¾“å…¥ã€‚

åœ¨ 2024â€“2025 å¹´çš„ç‰ˆæœ¬ä¸­ï¼ˆå°¤å…¶é…åˆ **LCEL** + **ChatOpenAI**ï¼‰ï¼Œå·²ç»å¯ä»¥æ— ç¼æ”¯æŒï¼š

- å›¾åƒï¼ˆimageï¼‰
- éŸ³é¢‘ï¼ˆaudioï¼‰
- æ–‡æœ¬ï¼ˆtextï¼‰
- æ–‡ä»¶ï¼ˆpdfã€excelã€json ç­‰ç»“æ„åŒ–è¾“å…¥ï¼‰

------



### **2ï¸âƒ£ å›¾åƒè¾“å…¥ç¤ºä¾‹ï¼ˆOpenAI GPT-4o / Claude 3 / Gemini ç­‰ï¼‰**



```
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
from langchain.schema.messages import HumanMessage

llm = ChatOpenAI(model="gpt-4o")  # æ”¯æŒå¤šæ¨¡æ€

msg = HumanMessage(
    content=[
        {"type": "text", "text": "æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹"},
        {"type": "image_url", "image_url": "https://example.com/dog.jpg"},
    ]
)

response = llm.invoke([msg])
print(response.content)
```

> âœ… GPT-4oã€Claude 3ã€Gemini Pro Vision éƒ½å¯ä»¥ç›´æ¥ç”¨è¿™ç§æ¶ˆæ¯ç»“æ„ã€‚



------



### **3ï¸âƒ£ éŸ³é¢‘è¾“å…¥ç¤ºä¾‹ï¼ˆè¯­éŸ³è¯†åˆ« + æ–‡æœ¬ç†è§£ï¼‰**



```
from langchain.chat_models import ChatOpenAI
from langchain.schema import HumanMessage

llm = ChatOpenAI(model="gpt-4o")

msg = HumanMessage(
    content=[
        {"type": "text", "text": "è¯·å¸®æˆ‘æ€»ç»“è¿™æ®µè¯­éŸ³çš„ä¸»è¦å†…å®¹"},
        {"type": "input_audio", "input_audio": "file://path/to/audio.mp3"},
    ]
)

response = llm.invoke([msg])
print(response.content)
```

> å¯ä»¥ä¸ Whisper æˆ–ç¬¬ä¸‰æ–¹è¯­éŸ³è¯†åˆ«æ¨¡å‹ç»“åˆï¼Œå®ç°ã€ŒéŸ³é¢‘ â†’ æ–‡å­— â†’ è¯­ä¹‰åˆ†æã€ã€‚



------



### **4ï¸âƒ£ å¤šè¾“å…¥èåˆï¼ˆæ–‡æœ¬ + å›¾åƒ + æ•°æ®ï¼‰**



ä¾‹å¦‚ï¼š

è¾“å…¥ä¸€å¼ æˆªå›¾ + ä¸€æ®µæè¿° + ä¸€å¼ è¡¨æ ¼æ•°æ®ï¼Œè¯·æ¨¡å‹å¸®ä½ ç”ŸæˆæŠ¥å‘Šã€‚

```
from langchain.schema import HumanMessage

msg = HumanMessage(content=[
    {"type": "text", "text": "æ ¹æ®å›¾ç‰‡å’Œè¡¨æ ¼ï¼Œå†™ä¸€æ®µç®€çŸ­çš„åˆ†æ"},
    {"type": "image_url", "image_url": "https://example.com/chart.png"},
    {"type": "text", "text": "è¡¨æ ¼æ•°æ®ï¼š\nå¹´ä»½, é”€å”®é¢\n2023, 1200\n2024, 1600"},
])
```

è¿™ç§â€œå¤šé€šé“è¾“å…¥â€å°±æ˜¯å¤šæ¨¡æ€é“¾è·¯çš„å…¸å‹åšæ³•ã€‚

LangChain çš„ **LCEL**ï¼ˆLangChain Expression Languageï¼‰å¯ä»¥å¾ˆæ–¹ä¾¿åœ°å°è£…è¿™äº›è¾“å…¥è¾“å‡ºã€‚



------



### **5ï¸âƒ£ ç»“åˆ LangChain å·¥å…·çš„å¤šæ¨¡æ€åœºæ™¯**



| **æ¨¡æ€**    | **å·¥å…· / æ¨¡å‹**                  | **å¸¸è§ç”¨é€”**        |
| ----------- | -------------------------------- | ------------------- |
| å›¾åƒ â†’ æ–‡æœ¬ | GPT-4o, Claude 3, Gemini Vision  | å›¾ç‰‡ç†è§£ã€OCR       |
| æ–‡æœ¬ â†’ å›¾åƒ | DALL-E, Stable Diffusion         | ç”Ÿæˆå›¾ç‰‡            |
| éŸ³é¢‘ â†’ æ–‡æœ¬ | Whisper, OpenAI Audio API        | è¯­éŸ³è¯†åˆ«            |
| æ–‡æœ¬ â†’ è¯­éŸ³ | TTS API                          | è¯­éŸ³è¾“å‡º            |
| æ–‡ä»¶è¾“å…¥    | DocumentLoaderï¼ˆPDFã€CSVã€DOCXï¼‰ | æ–‡ä»¶é—®ç­” / çŸ¥è¯†æŠ½å– |



------



## **âš™ï¸ äºŒã€è‡ªå®šä¹‰è¾“å‡ºï¼ˆStructured / Controlled Outputï¼‰**



æ¨¡å‹è¾“å‡ºå¦‚æœåªæ˜¯çº¯æ–‡æœ¬ï¼Œå¾ˆéš¾è¢«åç»­ç³»ç»Ÿç›´æ¥åˆ©ç”¨ã€‚

LangChain æä¾›äº†å¤šä¸ªå±‚çº§çš„â€œç»“æ„åŒ–è¾“å‡ºâ€èƒ½åŠ›ã€‚



------



### **1ï¸âƒ£ æœ€ç®€å•ï¼šStrOutputParser**



```
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.schema.output_parser import StrOutputParser

prompt = ChatPromptTemplate.from_template("å†™ä¸€å¥æè¿°çŒ«çš„å¥å­")
chain = prompt | ChatOpenAI(model="gpt-4o") | StrOutputParser()
print(chain.invoke({}))
```

> è¾“å‡ºæ˜¯çº¯æ–‡æœ¬ã€‚

------



### **2ï¸âƒ£ ç»“æ„åŒ–è¾“å‡ºï¼šJSON / Pydantic**



LangChain çš„ StructuredOutputParser å’Œ PydanticOutputParser æ˜¯å…³é”®ã€‚



#### **ç¤ºä¾‹ï¼ˆJSON ç»“æ„è¾“å‡ºï¼‰**



```
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import StructuredOutputParser, ResponseSchema

response_schemas = [
    ResponseSchema(name="name", description="å® ç‰©çš„åå­—"),
    ResponseSchema(name="species", description="å® ç‰©çš„ç§ç±»"),
]

parser = StructuredOutputParser.from_response_schemas(response_schemas)
format_instructions = parser.get_format_instructions()

prompt = ChatPromptTemplate.from_template(
    "è¯·ç”¨JSONæ ¼å¼å›ç­”ä»¥ä¸‹é—®é¢˜ï¼š\n{format_instructions}\né—®é¢˜: æè¿°ä½ ç†æƒ³çš„å® ç‰©ã€‚"
)

chain = prompt | ChatOpenAI(model="gpt-4o") | parser
print(chain.invoke({"format_instructions": format_instructions}))
```

è¾“å‡ºç¤ºä¾‹ï¼š

```
{"name": "å–µå–µ", "species": "çŒ«"}
```



------



### **3ï¸âƒ£ Pydantic æ¨¡å‹è¾“å‡ºï¼ˆå¼ºç±»å‹ç»“æ„ï¼‰**



```
from pydantic import BaseModel, Field
from langchain.output_parsers import PydanticOutputParser
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI

class ProductInfo(BaseModel):
    name: str = Field(description="å•†å“åç§°")
    price: float = Field(description="ä»·æ ¼")
    category: str = Field(description="ç±»åˆ«")

parser = PydanticOutputParser(pydantic_object=ProductInfo)
prompt = ChatPromptTemplate.from_template(
    "æ ¹æ®æè¿°ç”Ÿæˆå•†å“ä¿¡æ¯ã€‚\n{format_instructions}\næè¿°ï¼š{desc}"
)

chain = prompt | ChatOpenAI(model="gpt-4o") | parser
result = chain.invoke({
    "desc": "ä¸€æ¬¾å”®ä»·399å…ƒçš„è“ç‰™è€³æœºï¼Œé€‚åˆè¿åŠ¨ä½¿ç”¨ã€‚",
    "format_instructions": parser.get_format_instructions(),
})

print(result)
```

> è¾“å‡ºæ˜¯ä¸€ä¸ª ProductInfo å¯¹è±¡ï¼Œå¯ç›´æ¥ç”¨äºæ•°æ®åº“æˆ–APIå“åº”ã€‚



------



### **4ï¸âƒ£ è‡ªå®šä¹‰è¾“å‡ºé€»è¾‘ï¼ˆè‡ªå®šä¹‰ Parserï¼‰**



ä½ å¯ä»¥ç»§æ‰¿ BaseOutputParser æ¥å®šä¹‰ä»»æ„è§£æé€»è¾‘ï¼š

```
from langchain.schema import BaseOutputParser

class CodeBlockParser(BaseOutputParser):
    def parse(self, text: str):
        code = text.split("```")[1] if "```" in text else text
        return code.strip()

parser = CodeBlockParser()
```

ç„¶åæ”¾å…¥ LCEL ç®¡é“ä¸­ï¼š

```
chain = prompt | ChatOpenAI(model="gpt-4o") | parser
```



------



### **5ï¸âƒ£ ç»“åˆå¤šæ¨¡æ€è¾“å‡ºï¼ˆä¾‹å¦‚å›¾åƒæè¿°ç»“æ„åŒ–ï¼‰**



è¾“å…¥å›¾åƒ â†’ è¾“å‡ºç»“æ„åŒ– JSONï¼ˆå¦‚æ£€æµ‹ç»“æœï¼‰

```
prompt = ChatPromptTemplate.from_template(
    "åˆ†æå›¾ç‰‡ä¸­çš„ç‰©ä½“å¹¶è¾“å‡ºJSONï¼š{format_instructions}"
)

response_schemas = [
    ResponseSchema(name="objects", description="æ£€æµ‹åˆ°çš„ç‰©ä½“åˆ—è¡¨"),
    ResponseSchema(name="scene", description="åœºæ™¯æè¿°"),
]
parser = StructuredOutputParser.from_response_schemas(response_schemas)

msg = {
    "type": "image_url",
    "image_url": "https://example.com/street.jpg"
}

chain = (prompt | ChatOpenAI(model="gpt-4o") | parser)
print(chain.invoke({"format_instructions": parser.get_format_instructions(), "image": msg}))
```



------



## **ğŸ§  ä¸‰ã€LCEL æµå¼ç»„åˆï¼ˆå¤šæ¨¡æ€ + è‡ªå®šä¹‰è¾“å‡ºï¼‰**



ç”¨ LCEL å¯ä»¥åƒ Unix ç®¡é“ä¸€æ ·ï¼Œå°†ï¼š



> è¾“å…¥ â†’ å¤šæ¨¡æ€èåˆ â†’ æ¨¡å‹ â†’ è¾“å‡ºè§£æ â†’ è¿”å›ç»“æ„

```
from langchain.schema import HumanMessage
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.output_parsers import StrOutputParser

prompt = ChatPromptTemplate.from_template("æè¿°å›¾ç‰‡å†…å®¹ã€‚")
model = ChatOpenAI(model="gpt-4o")
parser = StrOutputParser()

workflow = prompt | model | parser

msg = HumanMessage(content=[
    {"type": "text", "text": "è¯·æè¿°è¿™å¼ å›¾ç‰‡"},
    {"type": "image_url", "image_url": "https://example.com/cat.png"}
])

result = workflow.invoke({"input": msg})
print(result)
```



------



## **ğŸ“Š å››ã€å®é™…å·¥ç¨‹åœºæ™¯å»ºè®®**



| **åœºæ™¯**      | **è¾“å…¥æ¨¡æ€** | **è¾“å‡ºæ ¼å¼**    | **æ¨èæ–¹æ¡ˆ**           |
| ------------- | ------------ | --------------- | ---------------------- |
| æ™ºèƒ½é—®ç­”      | æ–‡æœ¬         | Markdown / JSON | StructuredOutputParser |
| å›¾åƒç†è§£      | å›¾åƒ + æ–‡æœ¬  | JSON            | ChatOpenAI(gpt-4o)     |
| æ–‡ä»¶æ‘˜è¦      | æ–‡æœ¬ + æ–‡ä»¶  | æ®µè½ / åˆ—è¡¨     | LCEL + StrOutputParser |
| è¯­éŸ³åŠ©ç†      | éŸ³é¢‘ + æ–‡æœ¬  | çº¯æ–‡æœ¬ / JSON   | Whisper + ChatOpenAI   |
| Agentå·¥å…·è°ƒç”¨ | æ–‡æœ¬         | Pydanticç»“æ„    | PydanticOutputParser   |



------



## **âœ… æ€»ç»“å¯¹ç…§è¡¨**



| **åŠŸèƒ½**     | **æ ¸å¿ƒæ¨¡å—**                                 | **å…³é”®ç‚¹**              |
| ------------ | -------------------------------------------- | ----------------------- |
| å¤šæ¨¡æ€è¾“å…¥   | HumanMessage(content=[{"type":...}])         | æ”¯æŒ text, image, audio |
| å¤šæ¨¡æ€æ¨¡å‹   | ChatOpenAI(gpt-4o)ã€Claude 3                 | Vision æ¨¡å‹             |
| è‡ªå®šä¹‰è¾“å‡º   | StructuredOutputParser, PydanticOutputParser | ç»“æ„åŒ–JSON              |
| è‡ªå®šä¹‰è§£æå™¨ | ç»§æ‰¿ BaseOutputParser                        | å¤„ç†ç‰¹å®šæ ¼å¼            |
| æµå¼ç»„åˆ     | LCEL (`prompt                                | model                   |



------

