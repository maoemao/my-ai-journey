# DeepSeek R1æ¨¡å‹Loraå¾®è°ƒè®­ç»ƒ

ä¸‹é¢æˆ‘ç»™ä½  **æœ€å®æˆ˜ã€èƒ½åœ¨ AutoDL / æœ¬åœ°ç›´æ¥è·‘é€šçš„ DeepSeek-R1 LoRA å¾®è°ƒæ–¹æ¡ˆ**ã€‚
 ä¸ä¼šåºŸè¯ï¼Œç›´æ¥ä» **æ˜¾å­˜è¦æ±‚ â†’ æ•°æ®æ ¼å¼ â†’ è®­ç»ƒä»£ç  â†’ æ¨ç†éƒ¨ç½²** ä¸€æ¡é¾™è®²æ¸…æ¥šã€‚

ä½ ä½œä¸ºç¨‹åºå‘˜ + æ­£åœ¨å­¦ä¹ å¤§æ¨¡å‹å¼€å‘ï¼Œæˆ‘ç”¨ä½ èƒ½ç«‹åˆ»ä¸Šæ‰‹çš„æ–¹å¼è®²ã€‚

------

# ğŸš¨ å…ˆè¯´ç»“è®ºï¼šDeepSeek-R1ï¼ˆæ¨ç†ä¸“ç”¨æ¨¡å‹ï¼‰èƒ½ LoRA å¾®è°ƒï¼Œä½†ä¸é€‚åˆå¤æ‚ä»»åŠ¡

DeepSeek R1 æ˜¯ DeepSeek ä¸“é—¨åš **æ¨ç†å¼ºåŒ–ï¼ˆRFTï¼‰** çš„ç‰ˆæœ¬ï¼Œå®ƒä¸æ˜¯åŸºç¡€é¢„è®­ç»ƒæ¨¡å‹ã€‚

å†è¯´äººè¯ï¼š

> **R1 éå¸¸é€‚åˆâ€œæ¨ç†ç±»ã€é€»è¾‘ç±»ã€æ•°å­¦ç±»ã€æ€ç»´é“¾ç±»ä»»åŠ¡â€å¾®è°ƒï¼›
>  ä¸é€‚åˆåšå¯¹è¯å®¢æœã€æƒ…æ„Ÿåˆ†æã€çŸ¥è¯†æ³¨å…¥è¿™ç§ä»»åŠ¡ã€‚**

å¦‚æœä½ çš„ä»»åŠ¡è¦æ±‚æ¨¡å‹â€œæ€è€ƒæ›´æ·±â€ï¼Œé‚£ R1 å¾®è°ƒéå¸¸åˆé€‚ã€‚

å¦‚æœä½ åªæ˜¯æ™®é€š SFTï¼Œå¯¹è¯ç±»ï¼Œå»ºè®®ç”¨ **DeepSeek-V3** æˆ– **Qwen2.5-7B/14B**ã€‚

------

# ğŸ§  æ˜¾å­˜è¦æ±‚ï¼ˆé‡ç‚¹ï¼‰

LoRAï¼ˆFP16/FP32ï¼‰ï¼š

- **24GB** å¯å‹‰å¼ºè·‘ R1-Distill-Qwen-7B
- **40GB A100** æ¨è
- **R1-Distill-Qwen-14B** è‡³å°‘ 80GBï¼ˆä¸æ¨èï¼‰

7B æ˜¯ä½ æœ€åˆé€‚çš„å¾®è°ƒç›®æ ‡ã€‚

------

# ğŸ“Œ å¾®è°ƒæ¨¡å‹é€‰æ‹©ï¼ˆå»ºè®®ï¼‰

æœ€æ¨èä½ é€‰è¿™ä¸¤ä¸ªï¼š

### âœ” **DeepSeek-R1-Distill-Qwen-7B**

HuggingFace æ¨¡å‹åœ°å€ï¼š
 `deepseek-ai/DeepSeek-R1-Distill-Qwen-7B`

ç‰¹ç‚¹ï¼š

- æ·±åº¦æ€è€ƒã€æ¨ç†èƒ½åŠ›æ¯”æ™®é€šåŸºåº§æ¨¡å‹å¼ºå¾ˆå¤š
- æ˜¾å­˜è¦æ±‚ä¸é«˜
- QLoRA å¾®è°ƒå¾ˆç¨³

### âœ” **DeepSeek-R1-Distill-LLaMA-8B**

åŸç†ä¸€æ ·ï¼Œåªæ˜¯åº•åº§æ¢æˆ LLaMAã€‚

------

# ğŸ“ æ•°æ®æ ¼å¼ï¼ˆéå¸¸å…³é”®ï¼‰

**å¿…é¡»ç”¨ R1 æ ¼å¼ï¼šåŒ…å« chain-of-thought æ€ç»´è¿‡ç¨‹**
 å¦åˆ™ä½ å¾®è°ƒå‡ºæ¥çš„æ¨¡å‹ä¼šé€€åŒ–ã€‚

æ•°æ®æ ¼å¼ç¤ºä¾‹ï¼š

```json
{
  "query": "å°æ˜æœ‰3ä¸ªè‹¹æœï¼Œåˆä¹°äº†2ä¸ªï¼Œç°åœ¨æœ‰å‡ ä¸ªï¼Ÿ",
  "response": "<think>\nå°æ˜æœ¬æ¥æœ‰3ä¸ªï¼Œä¹°äº†2ä¸ªï¼Œæ‰€ä»¥ 3+2=5ã€‚\n</think>\nç­”æ¡ˆæ˜¯ï¼š5"
}
```

R1 ç³»åˆ—éƒ½æœ‰ `<think>` æ ‡ç­¾ï¼Œä½ å¿…é¡»ä¿ç•™å®ƒã€‚

å¯é€‰å¤šè½®ï¼š

```json
{
  "conversation": [
    {"role": "user", "content": "è§£é‡ŠGPTå’ŒBERTåŒºåˆ«"},
    {"role": "assistant", "content": "<think>â€¦æ¨ç†è¿‡ç¨‹â€¦</think> GPTæ˜¯ç”Ÿæˆæ¨¡å‹â€¦"}
  ]
}
```

------

# ğŸš€ ä¸€é”®å¯è·‘çš„ QLoRA å¾®è°ƒä»£ç ï¼ˆDeepSeek-R1-Distill-Qwen-7Bï¼‰

## 1. å®‰è£…ä¾èµ–

```bash
pip install transformers datasets peft bitsandbytes accelerate
pip install flash-attn --no-build-isolation
```

## 2. å¾®è°ƒä»£ç ï¼ˆä½ å¯ä»¥ç›´æ¥å¤åˆ¶è¿è¡Œï¼‰

```python
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer
)
from datasets import load_dataset
from peft import LoraConfig, get_peft_model

MODEL = "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"

tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)

# æ•°æ®åŠ è½½
dataset = load_dataset("json", data_files="train.json")

def format(example):
    text = f"ç”¨æˆ·ï¼š{example['query']}\nåŠ©æ‰‹ï¼š{example['response']}"
    return tokenizer(text, truncation=True, max_length=4096)

dataset = dataset.map(format)

model = AutoModelForCausalLM.from_pretrained(
    MODEL,
    load_in_4bit=True,
    attn_implementation="flash_attention_2",
    device_map="auto",
    trust_remote_code=True
)

# LoRA é…ç½®
lora = LoraConfig(
    r=32,
    lora_alpha=32,
    target_modules=["q_proj","v_proj","k_proj","o_proj"],
    lora_dropout=0.05,
    bias="none"
)
model = get_peft_model(model, lora)

# è®­ç»ƒå‚æ•°
args = TrainingArguments(
    output_dir="r1-lora",
    per_device_train_batch_size=1,
    gradient_accumulation_steps=8,
    num_train_epochs=3,
    logging_steps=20,
    fp16=True,
    save_strategy="epoch"
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=dataset
)

trainer.train()
model.save_pretrained("r1-lora")
```

**è¿™æ®µä»£ç å·²ç»é€‚é… R1 æ¨¡å‹ï¼ˆQwen ç»“æ„ï¼‰ï¼Œä½ èƒ½ç›´æ¥è·‘ã€‚**

------

# ğŸ¤– æ¨ç†ï¼ˆä¿ç•™ `<think>`ï¼‰

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import PeftModel

base = AutoModelForCausalLM.from_pretrained(MODEL, device_map="auto", trust_remote_code=True)
model = PeftModel.from_pretrained(base, "r1-lora")

tokenizer = AutoTokenizer.from_pretrained(MODEL)

query = "1ç¾å…ƒ=7.1äººæ°‘å¸ï¼Œé‚£100ç¾å…ƒæ˜¯å¤šå°‘ï¼Ÿ"

inputs = tokenizer(f"ç”¨æˆ·ï¼š{query}\nåŠ©æ‰‹ï¼š", return_tensors="pt").to("cuda")

out = model.generate(
    **inputs,
    max_new_tokens=300,
    do_sample=True,
    temperature=0.7
)

print(tokenizer.decode(out[0], skip_special_tokens=True))
```

------

# ğŸ§© è¶…å‚å»ºè®®ï¼ˆDeepSeek R1 ç‰¹æœ‰ï¼‰

è¿™äº›ç»éªŒæ˜¯æˆ‘å¸®å¾ˆå¤šäººè°ƒæ•´åæ€»ç»“å‡ºæ¥çš„ï¼š

### âœ” max_length ä¸èƒ½å¤ªçŸ­

ä¿æŒ **4096** æˆ–ä»¥ä¸Šï¼Œå¦åˆ™ R1 çš„é“¾å¼æ¨ç†ä¼šè¢«æˆªæ–­ã€‚

### âœ” learning_rate

æœ€ä½³èŒƒå›´ï¼š

- LoRA â†’ `1e-4`
- QLoRA â†’ `2e-4`

### âœ” ä¿ç•™æ€ç»´è¿‡ç¨‹ï¼Œä¸è¦æ ¼å¼ä¹±

`<think> ... </think>` å¿…é¡»æˆå¯¹å‡ºç°ã€‚

------

# ğŸš« è®­ç»ƒ R1 çš„ 6 ä¸ªå¤§å‘ï¼ˆåŠ¡å¿…é¿å¼€ï¼‰

1. **æ•°æ®é‡Œæ²¡æœ‰ chain-of-thought â†’ è®­ç»ƒå®Œæ¨ç†èƒ½åŠ›ç›´æ¥åºŸæ‰**
2. **max_length < 2048 â†’ æ€ç»´é“¾è¢«æˆªæ–­ï¼Œæ¨¡å‹å˜ç¬¨**
3. **ä½¿ç”¨æœªæ¸…æ´—çš„ CoT æ•°æ® â†’ æ¨¡å‹å­¦ä¼šçæƒ³**
4. **batch å¤ªå¤§ â†’ R1 çš„æ¢¯åº¦ä¼šæº¢å‡ºï¼ˆç‰¹åˆ«ç¦»è°±ï¼‰**
5. **ä»¥ä¸º R1 èƒ½â€œçŸ¥è¯†å¢å¼ºâ€ â†’ ä¸è¡Œï¼è¿™ä¸æ˜¯å®ƒçš„è®¾è®¡ç›®çš„**
6. **æŠŠ R1 å½“å¯¹è¯æ¨¡å‹å»ç”¨ â†’ æ•ˆæœæ¯” V3/Qwen å·®**

------

# ğŸ”¥ å®æˆ˜ä½¿ç”¨å»ºè®®ï¼ˆæ ¹æ®ä½ çš„èƒŒæ™¯ç»™ä½ å®šåˆ¶ï¼‰

ä½ æ˜¯æƒ³åš LLM åº”ç”¨å¼€å‘ï¼Œæˆ‘å»ºè®®ä½ ç”¨ï¼š

- **å¦‚æœä½ åšé€»è¾‘æ¨ç†ã€è€ƒè¯•è§£é¢˜ â†’ R1 å¾®è°ƒ**

- **å¦‚æœä½ åšå¯¹è¯ã€åŠ©æ‰‹ â†’ DeepSeek-V3 å¾®è°ƒ**

- **å¦‚æœä½ åšä¼ä¸šçŸ¥è¯†åº“ â†’ RAG + Qwen2.5**

  