# LangChain 消息管理与聊天历史存储

非常好，猫哥，你问到的是 LangChain **在对话类应用中最容易踩坑**、同时也是最关键的一环——

> **消息管理（Message Management）与聊天历史（Chat History）存储。**



很多人只知道用 LLMChain 调用模型，但一旦涉及多轮对话，就会发现模型“失忆”、上下文错乱、Token 过多。

LangChain 专门设计了完整的 **Memory 体系** 来解决这个问题。

我来系统讲一下：

------



## **🧩 一、LangChain 中的消息与对话模型结构**



LangChain 把聊天内容抽象成两层结构：

| **层级**                    | **类名**                               | **作用**         |
| --------------------------- | -------------------------------------- | ---------------- |
| **消息（Message）**         | AIMessage, HumanMessage, SystemMessage | 一条对话记录     |
| **消息历史（ChatHistory）** | BaseChatMessageHistory                 | 存储整个对话会话 |

> 这两层结构为 “Memory” 模块 提供基础支撑。



------



## **🧱 二、Memory（记忆模块）的核心作用**



Memory 是 LangChain 中用来**在多轮对话中保存上下文状态**的组件。

它的本质就是：



> 在每次调用模型前，把历史消息整理成 prompt 的一部分。



------



## **⚙️ 三、常见 Memory 类型（重点）**



| **类型**                           | **功能**                | **特点**       | **使用场景**      |
| ---------------------------------- | ----------------------- | -------------- | ----------------- |
| **ConversationBufferMemory**       | 缓存全部历史消息        | 最简单、无裁剪 | 小规模对话        |
| **ConversationBufferWindowMemory** | 只保留最近 N 轮对话     | 控制 token     | 聊天场景          |
| **ConversationSummaryMemory**      | 自动总结旧内容          | 节省上下文     | 长会话            |
| **ConversationTokenBufferMemory**  | 按 token 限制上下文长度 | 动态裁剪       | 对 token 敏感场景 |
| **VectorStoreRetrieverMemory**     | 以知识库形式记忆        | 检索旧对话内容 | 智能知识聊天      |
| **CombinedMemory**                 | 多种 Memory 混合使用    | 灵活强大       | 高级 Agent        |



------



## **🧠 四、典型用法示例**



### **1️⃣ 缓存式记忆（最常用）**



```
from langchain.memory import ConversationBufferMemory
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI

memory = ConversationBufferMemory()
llm = ChatOpenAI(model="gpt-4o")
chain = ConversationChain(llm=llm, memory=memory)

chain.predict(input="你好，我叫猫哥。")
chain.predict(input="请问我刚才说我叫什么？")
```

输出：



> “你刚才说你叫猫哥。”



------



### **2️⃣ 窗口式记忆（控制上下文长度）**



```
from langchain.memory import ConversationBufferWindowMemory

memory = ConversationBufferWindowMemory(k=3)  # 只保留最近3轮
```



------



### **3️⃣ 自动摘要记忆**



当对话很长时，让模型自己概括旧内容：

```
from langchain.memory import ConversationSummaryMemory
from langchain.chat_models import ChatOpenAI

llm = ChatOpenAI(model="gpt-4o")
memory = ConversationSummaryMemory(llm=llm)
```

> 它在每次调用后自动调用一次 LLM，总结旧对话为短摘要，节省 token。



------



### **4️⃣ Token 限制式记忆**



控制上下文总长度：

```
from langchain.memory import ConversationTokenBufferMemory

memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=1000)
```



------



### **5️⃣ 知识记忆（Embedding 形式）**



让模型记住“事实性知识”或“用户长期信息”。

```
from langchain.memory import VectorStoreRetrieverMemory
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings

embedding = OpenAIEmbeddings()
vectorstore = FAISS.from_texts(["猫哥是程序员", "猫哥有一个4岁女儿"], embedding)
retriever = vectorstore.as_retriever()

memory = VectorStoreRetrieverMemory(retriever=retriever)
```

每次模型调用前，自动检索最相关记忆插入 prompt。



------



## **💾 五、消息历史存储方案（ChatHistory 持久化）**

Memory 默认是**内存态**的，不持久化。

在实际项目中（如 Dify、LangServe、Web 后端），必须**持久化历史消息**。



### **LangChain 提供的持久化实现：**



| **类**                    | **存储介质**        | **说明**       |
| ------------------------- | ------------------- | -------------- |
| ChatMessageHistory        | 内存                | 默认           |
| FileChatMessageHistory    | JSON 文件           | 简单开发调试用 |
| RedisChatMessageHistory   | Redis               | 生产推荐       |
| SQLChatMessageHistory     | SQLite / PostgreSQL | 长期记录       |
| MongoDBChatMessageHistory | MongoDB             | 聊天类产品常用 |



------



### **例：Redis 存储聊天记录**



```
from langchain.memory import ConversationBufferMemory
from langchain.memory.chat_message_histories import RedisChatMessageHistory

history = RedisChatMessageHistory(session_id="user_123", url="redis://localhost:6379/0")
memory = ConversationBufferMemory(chat_memory=history, return_messages=True)
```

> 每个用户 session_id 对应一个 Redis 键，消息会自动写入/读取。



------



## **📊 六、服务端场景设计建议**



| **场景**            | **建议方案**                                  |
| ------------------- | --------------------------------------------- |
| 普通聊天            | ConversationBufferWindowMemory + Redis 持久化 |
| 长对话 / 会议记录   | ConversationSummaryMemory                     |
| 智能客服 / 知识问答 | VectorStoreRetrieverMemory                    |
| 多Agent协作         | CombinedMemory                                |



------



## **🔍 七、消息链路监控**



可配合 **LangSmith** 或 **自定义 CallbackHandler** 来追踪每次对话上下文。

可以看到：

- 当前 Memory 状态（包含哪些历史）
- 每次调用使用的 prompt 内容
- 消息追加情况



------



## **🧠 八、进阶技巧**



1. **Memory + Tool Agent 混用**

   让 Agent 不仅能记住上下文，还能记住工具调用结果。

   （使用 AgentExecutor(memory=memory)）

2. **Memory 的冷热分层**

   

   - Redis 存最近 20 条；
   - MongoDB 存长期对话归档；
   - VectorStore 存 embedding 级记忆。

   

3. **用户画像记忆**

   把 Memory 的内容定期总结成“用户档案”，长期记忆使用。



------



## **✅ 九、总结表**



| **分类** | **模块**                                      | **功能**       | **是否持久化** |
| -------- | --------------------------------------------- | -------------- | -------------- |
| 短期记忆 | ConversationBufferMemory                      | 暂存上下文     | ❌              |
| 长期记忆 | ConversationSummaryMemory / VectorStoreMemory | 持续总结       | ✅              |
| 历史记录 | ChatMessageHistory / Redis / SQL              | 聊天日志       | ✅              |
| 统一接口 | ConversationChain(memory=...)                 | 自动注入上下文 | ✅              |



------



