# LangChainå‘é‡ç®¡ç†é«˜é˜¶æŒ‡å—

ä¸‹é¢æˆ‘ç»™ä½ ä¸€ä»½ **â€œå®æˆ˜ + æ¶æ„ + ä»£ç  + ç­–ç•¥â€å…¨è¦†ç›–çš„ã€ŠLangChain å‘é‡ç®¡ç†é«˜é˜¶æŒ‡å—ã€‹**ã€‚
 è¿™ä¸æ˜¯å¸¸è§„å…¥é—¨ï¼Œè€Œæ˜¯ä½ åšä¼ä¸šçº§ã€å¯ç»´æŠ¤ã€å¯æ‰©å±• RAG ç³»ç»Ÿæ—¶å¿…é¡»æŒæ¡çš„å†…å®¹ã€‚

æˆ‘é‡ç‚¹è®²ï¼š**åˆ†ç‰‡ã€Embeddingã€å‘é‡åº“ç»“æ„ã€ç´¢å¼•ç­–ç•¥ã€åˆ·æ–°æœºåˆ¶ã€æ£€ç´¢å¢å¼ºã€åˆ†å¸ƒå¼æ¶æ„ã€å‘ç‚¹**ã€‚

å†…å®¹ç›´ç™½ã€ä¸ç»•å¼¯ï¼Œä½ èƒ½ç«‹åˆ»ä¸Šæ‰‹ã€‚

------

# ğŸš€ ä¸€ã€LangChain å‘é‡ç®¡ç†çš„æ ¸å¿ƒç†å¿µ

å‘é‡ç®¡ç† = **åˆ†ç‰‡ + å‘é‡åŒ– + å­˜å‚¨ + æ£€ç´¢å¢å¼º + ç”Ÿå‘½å‘¨æœŸç®¡ç†**ã€‚

å®é™…ç”Ÿäº§ç¯å¢ƒè¿œä¸æ˜¯â€œæŠŠæ–‡æœ¬åˆ‡ç‰‡ â†’ å­˜å‘é‡åº“â€è¿™ä¹ˆç®€å•ï¼Œè€Œæ˜¯ï¼š

```
æºæ•°æ® â†’ æ–‡æ¡£è§£æ â†’ åˆ†ç‰‡ç­–ç•¥
      â†’ embedding é€‰æ‹©/é…ç½®
      â†’ å‘é‡åº“å†™å…¥ï¼ˆschema/metadataï¼‰
      â†’ ç´¢å¼•æ„å»º
      â†’ æ£€ç´¢ç­–ç•¥ï¼ˆTopK/Hybrid/Multistepï¼‰
      â†’ æ›´æ–°/åˆ é™¤/ç‰ˆæœ¬æ§åˆ¶
      â†’ æ€§èƒ½ä¼˜åŒ–ä¸æˆæœ¬æ§åˆ¶
```

ä¸‹é¢æˆ‘æŠŠè¿™äº›é€æ¡è®²é€ã€‚

------

# ğŸ§± äºŒã€åˆ†ç‰‡ï¼ˆChunkingï¼‰æ˜¯å‘é‡ç®¡ç†çš„çµé­‚

åˆ†ç‰‡ç­–ç•¥å†³å®š RAG çš„æœ€ç»ˆæ•ˆæœã€‚

## 1. å¸¸è§„å›ºå®šåˆ†ç‰‡ï¼ˆæœ€å·®ï¼Œä¸æ¨èï¼‰

```
chunk_size = 500
chunk_overlap = 100
```

ç¼ºç‚¹ï¼š

- ç ´åè¯­ä¹‰
- æ£€ç´¢å™ªå£°å¤§
- å›ç­”ç»å¸¸â€œæ²¡è¯´é‡ç‚¹â€

## 2. æŒ‰è¯­ä¹‰ + ç»“æ„åˆ†ç‰‡ï¼ˆå¼ºçƒˆæ¨èï¼‰

LangChain æ”¯æŒ **RecursiveCharacterTextSplitter**

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

splitter = RecursiveCharacterTextSplitter(
    chunk_size=512,
    chunk_overlap=80,
    separators=["\n## ", "\n### ", "\n", ".", "ã€‚", " "]
)
```

ä¼˜åŠ¿ï¼š

- å°½é‡ä¿æŒç»“æ„ä¸è¢«ç ´å
- ä¸­æ–‡/è‹±æ–‡éƒ½åˆç†åˆ†æ®µ
- å™ªå£°å¤§å¹…ä¸‹é™

## 3. Token-aware åˆ†ç‰‡ï¼ˆæœ€æ¨èï¼‰

ä¿è¯åˆ†ç‰‡ä¸è¶…è¿‡å‘é‡æ¨¡å‹æœ€å¤§ token

```python
from langchain.text_splitter import TokenTextSplitter

splitter = TokenTextSplitter(
    model_name="gpt-3.5-turbo",
    chunk_size=400,
    chunk_overlap=50
)
```

## 4. æŒ‰æ–‡æ¡£ç»“æ„åˆ‡ç‰‡ï¼ˆé«˜çº§ï¼‰

è¡¨æ ¼ã€æ ‡é¢˜ã€åˆ—è¡¨ã€æ®µè½åˆ†å¼€å¤„ç†ã€‚

å¯¹äºä¼ä¸šæ–‡æ¡£ï¼ˆåˆåŒã€æŠ€æœ¯æ–‡æ¡£ï¼‰æ•ˆæœæå¥½ã€‚

------

# ğŸš€ ä¸‰ã€Embeddingï¼ˆå†³å®šå‘é‡è´¨é‡ï¼‰

## 1. æœ€æ¨èçš„ Embeddingï¼ˆæˆªè‡³ 2025ï¼‰

æŒ‰æ•ˆæœæ’åºï¼š

1ï¸âƒ£ **OpenAI text-embedding-3-large**
 2ï¸âƒ£ **DeepSeek embeddingï¼ˆæ€§ä»·æ¯”é«˜ï¼‰**
 3ï¸âƒ£ **bge-large-zh-v1.5ï¼ˆä¸­æ–‡æœ€å¼ºå¼€æºï¼‰**
 4ï¸âƒ£ **jina-embeddings-v3**
 5ï¸âƒ£ **text-embedding-3-smallï¼ˆè½»é‡ï¼‰**

LangChain ç¤ºä¾‹ï¼š

```python
from langchain_community.embeddings import OpenAIEmbeddings

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-large",
    api_key="xxx"
)
```

ä¸­æ–‡ä»»åŠ¡ï¼ˆå…¬å¸å†…éƒ¨æ–‡æ¡£ï¼‰ï¼š

```python
from langchain_community.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-large-zh-v1.5"
)
```

**Embedding å½±å“>50%æ•ˆæœï¼Œä¸è¦çœé’±ã€‚**

------

# ğŸª¤ å››ã€å‘é‡åº“é€‰å‹ï¼ˆæŒ‰åœºæ™¯é€‰ï¼‰

| é€‰é¡¹         | ä¼˜ç‚¹               | ç¼ºç‚¹               | é€‚åˆ      |
| ------------ | ------------------ | ------------------ | --------- |
| **FAISS**    | æé€Ÿã€æœ¬åœ°è®­ç»ƒ     | ä¸æ”¯æŒå¢é‡ã€åˆ†å¸ƒå¼ | Demo/ç ”å‘ |
| **Chroma**   | è½»é‡ã€ç®€å•ã€ç¨³å®š   | å¤§è§„æ¨¡æ€§èƒ½ä¸è¶³     | ä¸­å°é¡¹ç›®  |
| **Milvus**   | åˆ†å¸ƒå¼ã€äº¿çº§è§„æ¨¡   | éœ€è¦è¿ç»´           | ä¼ä¸šç”Ÿäº§  |
| **Weaviate** | Graph + Vector å¼º  | æˆæœ¬é«˜             | é«˜çº§RAG   |
| **PGVector** | ç”¨ Postgres å°±èƒ½è·‘ | ç¨æ…¢               | ä¼ä¸šå†…ç½‘  |

å…¸å‹æ¨èï¼š

- ä¸ªäººé¡¹ç›® â†’ Chroma
- ä¼ä¸š â†’ Milvus / PGVector
- é«˜å¹¶å‘æ¨ç† â†’ Milvus

LangChain ç¤ºä¾‹ï¼ˆChromaï¼‰ï¼š

```python
from langchain_community.vectorstores import Chroma

vector_store = Chroma(
    collection_name="kb",
    embedding_function=embeddings,
    persist_directory="./db"
)
```

------

# ğŸ” äº”ã€æ£€ç´¢ç­–ç•¥ï¼ˆå†³å®š RAG å›ç­”è´¨é‡çš„å…³é”®ï¼‰

å‘é‡æ£€ç´¢ä¸ä»…æ˜¯â€œæŸ¥ TopKâ€ï¼Œè€Œæ˜¯å¤šç­–ç•¥ç»„åˆã€‚

------

## 1. åŸºç¡€ Top-Kï¼ˆç®€å•ä½†å¸¸å¸¸ä¸å¤Ÿï¼‰

```python
docs = vector_store.similarity_search(query, k=5)
```

------

## 2. **Hybrid Retrievalï¼ˆæœ€æ¨èï¼‰**

å‘é‡ + BM25 ç»„åˆï¼Œæ•ˆæœæœ€é«˜ã€‚

```python
from langchain.retrievers import BM25Retriever, EnsembleRetriever

bm25 = BM25Retriever.from_texts(texts)
vect = vector_store.as_retriever()

retriever = EnsembleRetriever(
    retrievers=[bm25, vect],
    weights=[0.4, 0.6]
)
```

è®© LLM èƒ½åŒæ—¶æ‰¾åˆ°ï¼š

- è¯­ä¹‰ç›¸ä¼¼å†…å®¹
- å…³é”®è¯å‘½ä¸­å†…å®¹

é€‚åˆæ³•å¾‹ã€æŠ€æœ¯ã€è¯´æ˜ä¹¦ã€ç³»ç»Ÿæ–‡æ¡£ã€‚

------

## 3. MultiQuery Retrieverï¼ˆè‡ªåŠ¨æ‰©å±•æŸ¥è¯¢ï¼‰

LLM è‡ªåŠ¨ç”Ÿæˆå¤šç§ query æ”¹å†™ï¼Œæé«˜å¬å›ç‡ã€‚

```python
from langchain.retrievers.multi_query import MultiQueryRetriever

retriever = MultiQueryRetriever.from_llm(
    retriever=vect,
    llm=ChatOpenAI()
)
```

------

## 4. Contextual Compressionï¼ˆæ™ºèƒ½å‹ç¼©ï¼‰

LLM æŠŠé•¿æ®µå†…å®¹å‹ç¼©æˆå…³é”®çŸ¥è¯†ã€‚

```python
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor

compressor = LLMChainExtractor.from_llm(ChatOpenAI())
retriever = ContextualCompressionRetriever(
    base_compressor=compressor,
    base_retriever=vect
)
```

é€‚åˆé•¿æ–‡ RAGã€‚

------

# ğŸ§© å…­ã€å‘é‡åº“æ›´æ–°ï¼ˆä¼ä¸šçº§å¿…é¡»å¤„ç†ï¼‰

## 1. å¢é‡æ›´æ–°ï¼ˆUpsertï¼‰

```python
vector_store.add_texts(new_docs)
```

## 2. åˆ é™¤ï¼ˆæ ¹æ® metadataï¼‰

```python
vector_store.delete(where={"source": "contract_v1"})
```

## 3. å…¨é‡é‡å»ºï¼ˆå®šæœŸï¼‰

æ¯ 7~30 å¤©å¯¹æ–‡æ¡£é‡æ–°åˆ†ç‰‡ + å‘é‡åŒ–ï¼Œä»¥å…â€œæ¼‚ç§»â€ã€‚

------

# âš™ï¸ ä¸ƒã€å‘é‡ç®¡ç†çš„æ¶æ„è®¾è®¡ï¼ˆæœ€ç»ˆä½ è¦åšåˆ°è¿™æ ·ï¼‰

```
                   æ–‡æ¡£ä¸Šä¼ 
                        â†“
               æ–‡æ¡£é¢„å¤„ç†ï¼ˆOCR/è§£æï¼‰
                        â†“
          åˆ†ç‰‡ï¼ˆç»“æ„åŒ– + è¯­ä¹‰åˆ‡ç‰‡ï¼‰
                        â†“
              Embeddingï¼ˆæ‰¹å¤„ç†ï¼‰
                        â†“
            å‘é‡åº“ï¼ˆChroma/Milvusï¼‰
                        â†“
  BM25ï¼ˆElasticsearch/Whooshï¼‰ â† å¯é€‰
                        â†“
         Hybrid / MultiQuery / Compression
                        â†“
                  LLMï¼ˆDeepSeekï¼‰
                        â†“
                æœ€ç»ˆ RAG ç­”æ¡ˆ
```

è¿™æ˜¯æˆç†Ÿç³»ç»Ÿçš„æ ‡å‡†ç»“æ„ã€‚

------

# ğŸ”¥ å…«ã€é«˜é˜¶æŠ€å·§ï¼ˆå…³é”®ä¼˜åŒ–ï¼‰

## âœ” 1. ä½¿ç”¨ rerank æ¨¡å‹ï¼ˆæ•ˆæœæå‡å·¨å¤§ï¼‰

ä¾‹å¦‚ bge-reranker-largeï¼š

```python
from langchain_community.cross_encoders import HuggingFaceCrossEncoder

reranker = HuggingFaceCrossEncoder("BAAI/bge-reranker-large")
```

å‘é‡å¬å›åªæ˜¯â€œç²—æ’â€ï¼Œcross encoder è´Ÿè´£â€œç²¾æ’â€ã€‚

ä¼ä¸šé¡¹ç›®å¿…å¤‡ã€‚

------

## âœ” 2. å¯¹ chunk å¼•å…¥ metadataï¼ˆå¤§å¹…æå‡ç»“æœï¼‰

ç¤ºä¾‹ï¼š

```python
{
  "source": "contract_23.pdf",
  "page": 5,
  "section": "term_definition"
}
```

å¥½å¤„ï¼š

- åˆ é™¤/æ›´æ–°æ›´å®¹æ˜“
- æ£€ç´¢æ›´ç²¾å‡†
- LLM å›ç­”æ›´å¯ä¿¡

------

## âœ” 3. å¯¹ Chunk ç”Ÿæˆ Mini Summaryï¼ˆå¤§å¹…æé«˜å‘é‡è´¨é‡ï¼‰

```python
from langchain_core.prompts import PromptTemplate
summary = llm("å¸®æˆ‘æ€»ç»“ä¸€ä¸‹è¿™æ®µè¯çš„ä¸»è¦å†…å®¹...")
```

ç”¨ summary + åŸæ–‡ä¸€èµ· embedding ä¼šæ˜æ˜¾æå‡è¯­ä¹‰æœç´¢èƒ½åŠ›ã€‚

------

# ğŸª¤ ä¹ã€å®é™…å‘ç‚¹ï¼ˆé¿å…æµªè´¹æ—¶é—´ï¼‰

1. **åªç”¨å‘é‡æ£€ç´¢ â†’ æ‰¾ä¸åˆ°é‡ç‚¹å†…å®¹**
    ä¸€å®šè¦ Hybridã€‚
2. **chunk å¤ªå¤§ â†’ å‘é‡æ— æ„ä¹‰**
    ç†æƒ³ chunk sizeï¼š300~800 tokensã€‚
3. **embedding å¤ªå¼±**
    æ¢ text-embedding-3-large æˆ– bge-largeã€‚
4. **æ²¡æœ‰ metadata â†’ æ°¸è¿œæ²¡æ³•åˆ é™¤/æ›´æ–°**
    åŠ¡å¿…åŠ  source/page/sectionã€‚
5. **å‘é‡åº“å†…æŸ¥è¯¢è¿‡å¤§ â†’ æ…¢**
    è¦æ‰©å±• Milvus/PGVector åˆ†åŒºã€‚

------

# ğŸ§  åã€å¦‚æœä½ æƒ³ç»§ç»­ï¼Œæˆ‘å¯ä»¥ç»™ä½ ï¼š

é€‰æ‹©ä½ éœ€è¦ï¼Œæˆ‘é©¬ä¸Šç»™ï¼š

### ğŸ“Œ 1. LangChain RAG ä¼ä¸šçº§å·¥ç¨‹æ¨¡æ¿ï¼ˆç›®å½•+ä»£ç ï¼‰

### ğŸ“Œ 2. LangChain + DeepSeek çš„æœ€ä½³ç»„åˆå®è·µ

### ğŸ“Œ 3. Hybridï¼ˆBM25 + Vectorï¼‰æ£€ç´¢å…¨é¡¹ç›®ç¤ºä¾‹

### ğŸ“Œ 4. LangChain å‘é‡åº“æ›´æ–°/ç‰ˆæœ¬ç®¡ç†æœºåˆ¶

### ğŸ“Œ 5. Long RAGï¼ˆè¶…é•¿æ–‡æ¡£ï¼‰çš„æ¶æ„æœ€ä½³æ–¹æ¡ˆ

### ğŸ“Œ 6. LlamaIndex â†” LangChain ç»„åˆæ¶æ„ï¼ˆæœ€å¼ºæ–¹æ¡ˆï¼‰

ä½ æƒ³è¦å“ªä¸€å—ï¼Ÿ